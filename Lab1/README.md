# Data Engineering Pipelines with Snowpark Python
This repository contains the code for the *Data Engineering Pipelines with Snowpark Python* Snowflake Quickstart.

### ➡️ For overview, prerequisites, and to learn more, complete this end-to-end tutorial [Data Engineering Pipelines with Snowpark Python](https://quickstarts.snowflake.com/guide/data_engineering_pipelines_with_snowpark_python/index.html?index=..%2F..index#0) on quickstarts.snowflake.com.

___
Here is an overview of what we'll build in this lab:

<img src="images/demo_overview.png" width=800px>

Fork repo for Lab 1 : https://github.com/VishalPrasanna11/SnowFlake-Guide-data-engineering-with-snowpark-python.git

Results of Lab1

**Step 1: Fork the repository to create your own copy of the project.**
<img src="Results/1-Forking.png" width="800px">

**Step 2: Set up your CodeSpace environment for development.**
<img src="Results/2-Setting-Up-CodeSpace.png" width="800px">

**Step 3: Configure your Snowflake environment with the necessary settings.**
<img src="Results/3-Setting-Up-Snowflake.png" width="800px">

**Step 4: Load the initial data tables into Snowflake.**
<img src="Results/4-Loading-The-Table.png" width="800px">

**Step 5: Import and process weather data for analysis.**
<img src="Results/5-Load_Weather_Data.png" width="800px">

**Step 6: Create a specialized view for Point of Sale (POS) data.**
<img src="Results/6-Create-POS-View.png" width="800px">

**Step 7: Implement a User-Defined Function (UDF) for temperature conversion.**
<img src="Results/7-Fahrenheit-to-Celsius-UDF.png" width="800px">

**Step 8: Create a stored procedure for updating order information.**
<img src="Results/8-Orders-Update-Sproc.png" width="800px">

**Step 9: Set up daily metrics aggregation for city-level analysis.**
<img src="Results/9-Daily-City-Metrics-Update.png" width="800px">

**Step 10.1: Begin orchestrating data pipeline jobs with task scheduling.**
<img src="Results/10-Orchestrate-Jobs-Part-1.png" width="800px">

**Step 10.2: Configure dependency chains between tasks in the workflow.**
<img src="Results/10-Orchestrate-Jobs-Part-2.png" width="800px">

**Step 10.3: Monitor task execution in the orchestrated pipeline.**
<img src="Results/10-Orchestrate-Jobs-Part-3.png" width="800px">

**Step 10.4: Add error handling and notifications to the task workflow.**
<img src="Results/10-Orchestrate-Jobs-Part-4.png" width="800px">

**Step 10.5: Implement advanced scheduling options for recurring tasks.**
<img src="Results/10-Orchestrate-Jobs-Part-5.png" width="800px">

**Step 10.6: Configure resource allocation for task execution.**
<img src="Results/10-Orchestrate-Jobs-Part-6.png" width="800px">

**Step 10.7: Finalize the orchestration with complete task graph visualization.**
<img src="Results/10-Orchestrate-Jobs-Part-7.png" width="800px">

**Step 11.1: Begin setting up incremental processing for data efficiency.**
<img src="Results/11-Process-Incrementally-Part1.png" width="800px">

**Step 11.2: Configure change detection for incremental updates.**
<img src="Results/11-Process-Incrementally-Part2.png" width="800px">

**Step 11.3: Implement merge operations for incremental data processing.**
<img src="Results/11-Process-Incrementally-Part3.png" width="800px">

**Step 11.4: Verify the effectiveness of the incremental processing approach.**
<img src="Results/11-Process-Incrementally-Part4.png.png" width="800px">

**Step 12.1: Set up continuous integration and deployment infrastructure.**
<img src="Results/12-Deploy-Via-CI-CD_Part-1.png" width="800px">

**Step 12.2: Configure automated testing in the CI/CD pipeline.**
<img src="Results/12-Deploy-Via-CI-CD_Part-2.png" width="800px">

**Step 12.3: Deploy the solution to production through the CI/CD pipeline.**
<img src="Results/12-Deploy-Via-CI-CD_Part-3.png" width="800px">

**Step 13: Clean up resources and complete the teardown process.**
<img src="Results/13-Teardown.png" width="800px">
